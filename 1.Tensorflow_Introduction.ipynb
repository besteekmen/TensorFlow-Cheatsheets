{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5140c7d0",
   "metadata": {},
   "source": [
    "# Introduction to Tensorflow\n",
    "\n",
    "In traditional programming rules have to be formulated manually to obtain answers for the provided data, whereas, Machine Learning algorithms automatically formulate the rules from the provided data and answers. TensorFlow is an open-source software library for Machine Learning and Artificial Intelligence.\n",
    "\n",
    "- __Learn TensorFlow:__ [TensorFlow Website](https://www.tensorflow.org/learn)\n",
    "- __TensorFlow in Colab:__ [TensorFlow Colab Video Series](https://www.youtube.com/playlist?list=PLQY2H8rRoyvyK5aEDAI3wUUqC_F0oEroL)\n",
    "- __Git Installation:__ [git-scm](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)\n",
    "\n",
    "- __Required Packages:__\n",
    "  - tensorflow==2.7.0 NOT but 2.11.0\n",
    "  - scikit-learn==1.0.1\n",
    "  - pandas==1.1.5\n",
    "  - matplotlib==3.2.2\n",
    "  - seaborn==0.11.2\n",
    "\n",
    "## Imports\n",
    "\n",
    "The required packages with selected versions are imported below. [TensorFlow](https://www.tensorflow.org/) is imported with `tf` for convention and ease of use. [`numpy`](https://numpy.org) is imported to represent data as arrays and to optimize numerical operations. The framework [`keras`](https://keras.io/) is also imported to use in order to build neural networks as a sequence of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93db3299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow-gpu\n",
      "Version: 2.10.1\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\programdata\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# To check the tensorflow package installed on the environment\n",
    "!pip show tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550ad2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.10.1\n",
      "Name: /physical_device:GPU:0   Type: GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "\n",
    "# Uncomment to see where the variables get placed\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# To make sure if the notebook is using GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f23c3a",
   "metadata": {},
   "source": [
    "## The Simplest Neural Network\n",
    "\n",
    "The simplest possible neural network is created with 1 layer with 1 neuron which has the input shape of only 1 value using Keras API's [Sequential](https://keras.io/api/models/sequential/) class as below. [Sequential](https://keras.io/api/models/sequential/) allows us to define a network as a __sequence__ of [layers](https://keras.io/api/layers/) while [Dense](https://keras.io/api/layers/core_layers/dense/) is used to define a layer of connected neurons.\n",
    "\n",
    "##### __Build the Model:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2403a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a simple sequential model\n",
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.output_shape\n",
    "\n",
    "# Same can also be done with incremental building\n",
    "# model = keras.Sequential()\n",
    "# model.add(layers.Dense(units=1, input_shape=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dc7841",
   "metadata": {},
   "source": [
    "##### __Compile the Model:__\n",
    "Now, you will compile the neural network. When you do so, you have to specify 2 functions: a [loss](https://keras.io/api/losses/) and an [optimizer](https://keras.io/api/optimizers/).\n",
    "\n",
    "If you've seen lots of math for machine learning, here's where it's usually used. But in this case, it's nicely encapsulated in functions and classes for you. But what happens here? Let's explain...\n",
    "\n",
    "You know that in the function declared at the start of this notebook, the relationship between the numbers is `y=2x-1`. When the computer is trying to 'learn' that, it makes a guess... maybe `y=10x+10`. The `loss` function measures the guessed answers against the known correct answers and measures how well or how badly it did.\n",
    "\n",
    "It then uses the `optimizer` function to make another guess. Based on how the loss function went, it will try to minimize the loss. At that point maybe it will come up with something like `y=5x+5`, which, while still pretty bad, is closer to the correct result (i.e. the loss is lower).\n",
    "\n",
    "It will repeat this for the number of _epochs_ which you will see shortly. But first, here's how you will tell it to use [mean squared error](https://keras.io/api/losses/regression_losses/#meansquarederror-function) for the loss and [stochastic gradient descent](https://keras.io/api/optimizers/sgd/) for the optimizer. You don't need to understand the math for these yet, but you can see that they work!\n",
    "\n",
    "Over time, you will learn the different and appropriate loss and optimizer functions for different scenarios. \n",
    "\n",
    "An optimization problem seeks to minimize a loss function.The optimizer figures out the next guess based on the loss function.\n",
    "Machine learning algorithms build a model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7144f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7481842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalar (rank 0)\n",
    "string = tf.Variable(\"a\", tf.string)\n",
    "int_var = tf.Variable(128, tf.int16)\n",
    "float_var = tf.Variable(3.147, tf.float64)\n",
    "bool_var = tf.Variable(False)\n",
    "complex_var = tf.Variable(5 + 4j)\n",
    "\n",
    "# higher rank\n",
    "rank_1 = tf.Variable([\"a\",\"b\",\"c\",\"d\"], tf.string)\n",
    "rank_2 = tf.Variable([[\"a\",\"b\"],[\"c\",\"d\"],[\"e\",\"f\"]], tf.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2bfa8e",
   "metadata": {},
   "source": [
    "#### 2.2. Rank, Dtype and Shape of Tensor\n",
    "\n",
    "A variable looks and acts like a tensor, and, in fact, is a data structure backed by a `tf.Tensor`. Like tensors, they have a `dtype` and a `shape`, and can be exported to NumPy. Also eash tensor has a `rank` which is the number of dimensions of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a719601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranks:\n",
      "- string: tf.Tensor(0, shape=(), dtype=int32)\n",
      "- rank_1: tf.Tensor(1, shape=(), dtype=int32)\n",
      "- rank_2: tf.Tensor(2, shape=(), dtype=int32)\n",
      "\n",
      "Shape:  (3, 2)\n",
      "DType:  <dtype: 'string'>\n",
      "As NumPy:  [[b'a' b'b']\n",
      " [b'c' b'd']\n",
      " [b'e' b'f']]\n"
     ]
    }
   ],
   "source": [
    "# rank/degree of a tensor\n",
    "print(\"Ranks:\")\n",
    "print(\"- string:\",tf.rank(string))\n",
    "print(\"- rank_1:\",tf.rank(rank_1))\n",
    "print(\"- rank_2:\",tf.rank(rank_2))\n",
    "\n",
    "# shape and dtype of a tensor\n",
    "print(\"\\nShape: \", rank_2.shape)\n",
    "print(\"DType: \", rank_2.dtype)\n",
    "print(\"As NumPy: \", rank_2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8cdab5",
   "metadata": {},
   "source": [
    "#### 2.3. Reshape Tensor\n",
    "\n",
    "Most tensor operations work on variables as expected, although variables cannot be reshaped. However, `tf.reshape` creates a new tensor with the desired shape if the total number of elements in the input tensor is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b37a8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]]], shape=(1, 2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]]], shape=(2, 1, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor([1. 1. 1. 1. 1. 1.], shape=(6,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tensor1 = tf.ones([1,2,3]) # tf.ones() creates a tensor with the given shape full of ones \n",
    "tensor2 = tf.reshape(tensor1, [2,1,3]) # reshape tensor1 to shape [2,3,1]\n",
    "tensor3 = tf.reshape(tensor1, [2,-1]) # -1 tells tensor to calculate the size of the dimension in that space\n",
    "tensor4 = tf.reshape(tensor1, [-1]) # -1 tells tensor to calculate the size of the dimension in that space\n",
    "\n",
    "print(tensor1)\n",
    "print(tensor2)\n",
    "print(tensor3)\n",
    "print(tensor4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73684e4e",
   "metadata": {},
   "source": [
    "#### 2.4. Tensor Types\n",
    "\n",
    "- Constant: `tf.constant` creates a constant tensor from a tensor-like object\n",
    "- Variable: `tf.Variable` creates a variable with the same dtype as the initialization value.\n",
    "- Placeholder\n",
    "- SparseTensor\n",
    "\n",
    "With the exception of `Variable`, all tensors are immutable and their value cannot change during the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8db56aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float64) tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32) <tf.Variable 'Variable:0' shape=(2, 3) dtype=float64, numpy=\n",
      "array([[1., 2., 3.],\n",
      "       [4., 5., 6.]])>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# constant tensor with given dtype and shape\n",
    "const_tensor = tf.constant([1, 2, 3, 4, 5, 6], dtype=tf.float64, shape=[2, 3])\n",
    "num_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "const_tensor2 = tf.constant(num_array)\n",
    "# variable tensor\n",
    "var_tensor = tf.Variable(const_tensor)\n",
    "\n",
    "print(const_tensor,const_tensor2,var_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32369ea3",
   "metadata": {},
   "source": [
    "#### 2.5. Assign and Duplicate Tensors\n",
    "A tensor can be reassigned using `tf.Variable.assign`.  Calling `assign` does not (usually) allocate a new tensor; instead, the existing tensor's memory is reused. Assing operation does not allow to resize the tensor. However, creating new variables from existing variables duplicates the backing tensors. Two variables will not share the same memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a730a9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 6.]\n",
      "[2. 3.]\n",
      "[7. 9.]\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([2.0, 3.0])\n",
    "# create b based on the value of a\n",
    "b = tf.Variable(a)\n",
    "a.assign([5, 6])\n",
    "\n",
    "# a and b are different\n",
    "print(a.numpy()) # [5. 6.]\n",
    "print(b.numpy()) # [2. 3.]\n",
    "\n",
    "# there are other versions of assign\n",
    "print(a.assign_add([2,3]).numpy())  # [7. 9.]\n",
    "print(a.assign_sub([7,9]).numpy())  # [0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2676843c",
   "metadata": {},
   "source": [
    "#### 2.6. Evaluating Tensors\n",
    "Since the tensors represent a partially completed computation, a session is run to evaluate the tensor. A simple way to do it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacec0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess: # creates a session using the default graph\n",
    "    tensor_name.eval() # evaluates the tensor with the name `tensor_name`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a255b",
   "metadata": {},
   "source": [
    "#### 2.7. Tensors Lifecycles, Naming and Watching\n",
    "In Python-based TensorFlow, `tf.Variable` instance have the same lifecycle as other Python objects. When there are no references to a variable it is automatically deallocated. Variables can also be named to track and debug. Two variables can be given the same name. Variable names are preserved when saving and loading models. By default, variables in models will acquire unique variable names automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1326f519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([False False], shape=(2,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# different tensors have the same name\n",
    "my_tensor1 = tf.Variable(const_tensor, name=\"Sample\")\n",
    "# new variable with the same name, but different value\n",
    "my_tensor2 = tf.Variable(const_tensor + 1, name=\"Sample\")\n",
    "\n",
    "# these are elementwise-unequal, despite having the same name\n",
    "print(a == b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ceef73",
   "metadata": {},
   "source": [
    "Although variables are important for differentiation, some variables will not need to be differentiated.  You can turn off gradients for a variable by setting `trainable` to false at creation. An example of a variable that would not need gradients is a training step counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d7d2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_counter = tf.Variable(1, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1ab8e",
   "metadata": {},
   "source": [
    "#### 2.8. Placing Variables and Tensors\n",
    "\n",
    "For better performance, TensorFlow will attempt to place tensors and variables on the fastest device compatible with its `dtype`. This means most variables are placed on a GPU if one is available. However, one can override this.  In this snippet, place a float tensor and a variable on the CPU, even if a GPU is available (see the placement with `tf.debugging.set_log_device_placement(True)`). \n",
    "\n",
    "__Note:__ Although manual placement works, using [distribution strategies](distributed_training.ipynb) can be a more convenient and scalable way to optimize the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c11911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('CPU:0'):\n",
    "    # create some tensors and place on CPU\n",
    "    a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9908af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "tf.Tensor(\n",
      "[[ 1.  4.  9.]\n",
      " [ 4. 10. 18.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('CPU:0'):\n",
    "    a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.Variable([[1.0, 2.0, 3.0]])\n",
    "\n",
    "with tf.device('GPU:0'):\n",
    "    # element-wise multiply\n",
    "    k = a * b\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba9722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tf2-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "6f3fc6488339c4e33b0cad7b2f11252c3ab69579f1539e25a75f6d6ccfe755bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
